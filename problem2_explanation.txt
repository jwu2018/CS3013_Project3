Problem 2: Synchronizing Shueâ€™s Sketchy Scientific Study
We approached the second problem by using an essentially "bruteforce" method that ensures that no deadlocks can occur from any test case scenario/combination of object instructions. To start the program, we declare four threads and pass in a struct that contains the name of the thread (the graduate student's name), as well as an array of names for the objects. In the grad student thread, each time the student wants to experiment on an object, it is forced to wait on the locks for each station that it needs listed in the instruction set for the object; this is effectively prevents any other object from coming into a deadlock conflict situation, since an object is not able to enter circulation in the system unless it can guarantee that its instructions won't overlap with another object's. Futhermore, we use a mutex lock that is locked at the beginning of the checks in order to ensure that one thread can't be switched to midway through the checks, in which case would cause the possibility of deadlock since the locks of the station needed by the former thread could overlap in the path of the latter thread: for example, if grad student 1 needed to acquire stations 1, 2, and 3 in that order, but between the acquisition of the locks for 2 and 3 the program switched to grad student 2 with the instruction set that required stations 3, 2, 1 in such order, then deadlock would occur since our method requires that an object claims all the locks for the stations it needs before progressing, and so in this scenario grad student 2 would be stuck with the lock for station 3 and waiting on station 2's lock while grad student 1 would be stuck with the lock for station 2 and waiting on the lock for station 3. Therefore the mutex lock that surrounds this critical section is needed in order for all locks to be acquired essentially simultaneously by a single thread. 
Once the thread acquires all the locks for the station it needs, the general lock is released and advances to carrying out the experiments at each station at which the lock is held; each time the experiment at a station is finished, the lock for that station is released, allowing for a sequential update of the locks held at the stations and for other threads to access the stations. No lock is needed to surround the section for releasing locks and experimentation, since a) this would dramatically decrease performance/parallelism as all threads must stop and wait for each experiment to finish in serial fashion, and b) it would not be necessary since all the stations needed for a student's object have already been reserved, so future objects would have to wait until all of the claimed stations are free before proceeding. Once an object has finished all of its instructions, the cycle repeats until all objects in a randomly generated list of objects/instructions are completed. 
In our solution to this problem, we prioritized the issue of resolving deadlock and ensuring mutex between threads over performance and fairness. However, in this given problem our solution is viable due to the controlled scale of the simulation, namely the number of threads that must concurrently run and share the limited amount of resources. This brings into consideration of the scalibility of our method: due to the nature of brute forcing, this solution only works efficiently due to the fact that only four threads are trying to run concurrently and that they can at most lock four stations that are shared by other threads; however, in the case that more threads are introduced or more resources are available to be locked down, the distrubution of the turnaround/response times for objects to complete experimentation scales linearly with the increase in threads/resources, causing worst case scenarios to become especially problematic when encountered (with only four threads and four stations, the max amount of time a thread could wait before starting is the total time a thread spends at each of the stations, which can thus be generalized to understand the worst case response time for any thread to be total amount of time spent at all of the stations). 
Another part of our solution to take into consideration would be the use of lock to control the order of what thread goes next over a queue or a condition variable. Consider the case where multiple grad students try to hold the lock for a station when a lock has already been held by an initial thread; because of how unlocking is implemented in the Pthreads library, a randomly selected thread waiting on the lock will be released, creating a neutral control of which thread is able to run regardless of the amount of instructions it requires for the object; in a queue implementation however, threads would be run in FIFO order, which would guarantee to an extent that a thread would be able to run at some point. The choice to use locks that chooses threads to run randomly over the use of a queue again stems from the size of the simulation, since at any given point only at most two threads could be selected randomly (where all four threads wants to hold the same station with one thread holding the lock for station itself, one holding the general mutex lock, and the other two waiting on the mutex lock); the additional benefit that the random selection provides over a queue is that threads that have the potential to finish quicker i.e., threads that require fewer stations would have the chance of being run, as opposed to being stuck behind a longer instruction set in a queue. 
The basis of our solution is from the producer/consumer problem mainly in the sense that essentially a shared "buffer" in the form of the stations are being shared among four consumer threads; in the solution presented by the textbook, consumers and producers essentially lock down the critical sections of the shared resources, which thus lends to our method since we essentially adapt the lockdown method of the shared resource in order to ensure mutex and prevent deadlock. 